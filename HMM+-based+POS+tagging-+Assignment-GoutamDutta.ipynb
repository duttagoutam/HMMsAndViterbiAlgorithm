{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# first few tagged sentences\n",
    "print(nltk_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95607"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged train words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20', 'billion', 'yen', 'of', '6']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12044\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))\n",
    "N_Words=int(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'ADV', 'ADJ', 'ADP', 'DET', 'NOUN', 'PRON', 'PRT', '.', 'X', 'NUM', 'CONJ', 'VERB'}\n",
      "ADV\n"
     ]
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "print(len(T))\n",
    "print(T)\n",
    "print(list(T)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 27420), ('VERB', 12894), ('.', 11108), ('ADP', 9380), ('DET', 8308)]\n"
     ]
    }
   ],
   "source": [
    "# most frequent tag in the corpus\n",
    "tags = [pair[1] for pair in train_tagged_words]\n",
    "tag_counts = Counter(tags)\n",
    "#print(tags)\n",
    "# the most common tags can be seen using the most_common() method of Counter\n",
    "most_common_tags =tag_counts.most_common(5)\n",
    "print(most_common_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged test words\n",
    "\n",
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chairman\n",
      "(0, 2151)\n",
      "(41, 27420)\n",
      "(0, 12894) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing the Emission Probability function\n",
    "print(\"\\n\", \"chairman\")\n",
    "print(word_given_tag('chairman', 'CONJ'))\n",
    "print(word_given_tag('chairman', 'NOUN'))\n",
    "print(word_given_tag('chairman', 'VERB'), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372, 27420)\n",
      "(4034, 27420)\n",
      "(69, 12894)\n",
      "(0, 0)\n",
      "(0, 11108)\n",
      "(0, 11108)\n",
      "(0, 11108)\n",
      "(0, 11108)\n"
     ]
    }
   ],
   "source": [
    "# testing Transition Probability\n",
    "print(t2_given_t1(t2='DET', t1='NOUN'))\n",
    "print(t2_given_t1('VERB', 'NOUN'))\n",
    "print(t2_given_t1('CONJ', 'VERB'))\n",
    "print(t2_given_t1(',', 'NNP'))\n",
    "print(t2_given_t1('DT', '.'))\n",
    "print(t2_given_t1('VBG', '.'))\n",
    "print(t2_given_t1('NN', '.'))\n",
    "print(t2_given_t1('NNP', '.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition matrix of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.83272460e-02, 1.28443405e-01, 1.18154660e-01, 6.87022880e-02,\n",
       "        3.25257219e-02, 1.55990710e-02, 1.39395948e-02, 1.36077002e-01,\n",
       "        2.32326593e-02, 3.28576155e-02, 6.96979742e-03, 3.45170915e-01],\n",
       "       [4.76034125e-03, 6.74655288e-02, 7.74786621e-02, 4.92449105e-03,\n",
       "        7.00262666e-01, 6.56598830e-04, 1.08338809e-02, 6.41825348e-02,\n",
       "        2.08470132e-02, 1.98621135e-02, 1.65791195e-02, 1.21470783e-02],\n",
       "       [1.38592748e-02, 1.05650321e-01, 1.64179113e-02, 3.23880583e-01,\n",
       "        3.23880583e-01, 6.80170581e-02, 1.38592755e-03, 3.96588482e-02,\n",
       "        3.50746252e-02, 6.26865700e-02, 8.52878438e-04, 8.63539428e-03],\n",
       "       [1.23976888e-02, 2.04742417e-01, 9.26817488e-03, 5.53683192e-03,\n",
       "        6.38902247e-01, 3.24987969e-03, 2.40731824e-04, 1.80548877e-02,\n",
       "        4.52575833e-02, 2.20269617e-02, 4.81463649e-04, 3.98411155e-02],\n",
       "       [1.70678329e-02, 1.21079506e-02, 1.77097008e-01, 1.35667399e-02,\n",
       "        2.64040858e-01, 4.70459508e-03, 4.38001454e-02, 2.39569664e-01,\n",
       "        2.88110860e-02, 9.37272049e-03, 4.27425243e-02, 1.47118896e-01],\n",
       "       [3.39244418e-02, 7.32459500e-02, 2.23592911e-02, 9.25212074e-03,\n",
       "        2.04317659e-01, 8.09560530e-03, 1.31071704e-02, 4.12490368e-02,\n",
       "        9.32922140e-02, 7.32459500e-03, 5.39707020e-03, 4.88434851e-01],\n",
       "       [1.01075973e-02, 8.47733915e-02, 2.11933479e-02, 1.03358328e-01,\n",
       "        2.49755457e-01, 1.82588845e-02, 1.95630919e-03, 4.07564379e-02,\n",
       "        1.36941634e-02, 5.51027060e-02, 2.28236057e-03, 3.98761004e-01],\n",
       "       [5.23046441e-02, 4.46525030e-02, 9.23658609e-02, 1.74288794e-01,\n",
       "        2.20021605e-01, 6.66186512e-02, 2.34065531e-03, 9.38962922e-02,\n",
       "        2.71876119e-02, 7.94022307e-02, 5.77961840e-02, 8.90349299e-02],\n",
       "       [2.58579403e-02, 1.75578613e-02, 1.44612923e-01, 5.36312833e-02,\n",
       "        6.22505993e-02, 5.55466898e-02, 1.84676781e-01, 1.63288102e-01,\n",
       "        7.50199556e-02, 1.75578613e-03, 1.05347168e-02, 2.05267355e-01],\n",
       "       [2.41327309e-03, 3.46908011e-02, 3.55957784e-02, 3.31825041e-03,\n",
       "        3.48717958e-01, 1.50829565e-03, 2.83559579e-02, 1.18853696e-01,\n",
       "        2.11463049e-01, 1.82202116e-01, 1.38763199e-02, 1.90045256e-02],\n",
       "       [5.43933064e-02, 1.18084610e-01, 5.20688035e-02, 1.21338911e-01,\n",
       "        3.52859139e-01, 5.76476045e-02, 4.64900024e-03, 3.39377038e-02,\n",
       "        7.90330116e-03, 4.13761027e-02, 4.64900048e-04, 1.55276611e-01],\n",
       "       [8.22087824e-02, 6.55343607e-02, 9.15154368e-02, 1.34170935e-01,\n",
       "        1.10516518e-01, 3.52877304e-02, 3.22630666e-02, 3.49775106e-02,\n",
       "        2.17077717e-01, 2.26461925e-02, 5.35132643e-03, 1.68450445e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>.</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.128443</td>\n",
       "      <td>0.118155</td>\n",
       "      <td>0.068702</td>\n",
       "      <td>0.032526</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.136077</td>\n",
       "      <td>0.023233</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.345171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.067466</td>\n",
       "      <td>0.077479</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.700263</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.064183</td>\n",
       "      <td>0.020847</td>\n",
       "      <td>0.019862</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.012147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.013859</td>\n",
       "      <td>0.105650</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.323881</td>\n",
       "      <td>0.323881</td>\n",
       "      <td>0.068017</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.039659</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.062687</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.008635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.204742</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.638902</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.018055</td>\n",
       "      <td>0.045258</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.017068</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>0.177097</td>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.264041</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.239570</td>\n",
       "      <td>0.028811</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.042743</td>\n",
       "      <td>0.147119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.033924</td>\n",
       "      <td>0.073246</td>\n",
       "      <td>0.022359</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>0.204318</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>0.041249</td>\n",
       "      <td>0.093292</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.488435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.084773</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.103358</td>\n",
       "      <td>0.249755</td>\n",
       "      <td>0.018259</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.040756</td>\n",
       "      <td>0.013694</td>\n",
       "      <td>0.055103</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.398761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.052305</td>\n",
       "      <td>0.044653</td>\n",
       "      <td>0.092366</td>\n",
       "      <td>0.174289</td>\n",
       "      <td>0.220022</td>\n",
       "      <td>0.066619</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.093896</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.079402</td>\n",
       "      <td>0.057796</td>\n",
       "      <td>0.089035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.025858</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>0.144613</td>\n",
       "      <td>0.053631</td>\n",
       "      <td>0.062251</td>\n",
       "      <td>0.055547</td>\n",
       "      <td>0.184677</td>\n",
       "      <td>0.163288</td>\n",
       "      <td>0.075020</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.205267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.034691</td>\n",
       "      <td>0.035596</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.348718</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.118854</td>\n",
       "      <td>0.211463</td>\n",
       "      <td>0.182202</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>0.019005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.054393</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.052069</td>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.352859</td>\n",
       "      <td>0.057648</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.041376</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.155277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.082209</td>\n",
       "      <td>0.065534</td>\n",
       "      <td>0.091515</td>\n",
       "      <td>0.134171</td>\n",
       "      <td>0.110517</td>\n",
       "      <td>0.035288</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.217078</td>\n",
       "      <td>0.022646</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.168450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADV       ADJ       ADP       DET      NOUN      PRON       PRT  \\\n",
       "ADV   0.078327  0.128443  0.118155  0.068702  0.032526  0.015599  0.013940   \n",
       "ADJ   0.004760  0.067466  0.077479  0.004924  0.700263  0.000657  0.010834   \n",
       "ADP   0.013859  0.105650  0.016418  0.323881  0.323881  0.068017  0.001386   \n",
       "DET   0.012398  0.204742  0.009268  0.005537  0.638902  0.003250  0.000241   \n",
       "NOUN  0.017068  0.012108  0.177097  0.013567  0.264041  0.004705  0.043800   \n",
       "PRON  0.033924  0.073246  0.022359  0.009252  0.204318  0.008096  0.013107   \n",
       "PRT   0.010108  0.084773  0.021193  0.103358  0.249755  0.018259  0.001956   \n",
       ".     0.052305  0.044653  0.092366  0.174289  0.220022  0.066619  0.002341   \n",
       "X     0.025858  0.017558  0.144613  0.053631  0.062251  0.055547  0.184677   \n",
       "NUM   0.002413  0.034691  0.035596  0.003318  0.348718  0.001508  0.028356   \n",
       "CONJ  0.054393  0.118085  0.052069  0.121339  0.352859  0.057648  0.004649   \n",
       "VERB  0.082209  0.065534  0.091515  0.134171  0.110517  0.035288  0.032263   \n",
       "\n",
       "             .         X       NUM      CONJ      VERB  \n",
       "ADV   0.136077  0.023233  0.032858  0.006970  0.345171  \n",
       "ADJ   0.064183  0.020847  0.019862  0.016579  0.012147  \n",
       "ADP   0.039659  0.035075  0.062687  0.000853  0.008635  \n",
       "DET   0.018055  0.045258  0.022027  0.000481  0.039841  \n",
       "NOUN  0.239570  0.028811  0.009373  0.042743  0.147119  \n",
       "PRON  0.041249  0.093292  0.007325  0.005397  0.488435  \n",
       "PRT   0.040756  0.013694  0.055103  0.002282  0.398761  \n",
       ".     0.093896  0.027188  0.079402  0.057796  0.089035  \n",
       "X     0.163288  0.075020  0.001756  0.010535  0.205267  \n",
       "NUM   0.118854  0.211463  0.182202  0.013876  0.019005  \n",
       "CONJ  0.033938  0.007903  0.041376  0.000465  0.155277  \n",
       "VERB  0.034978  0.217078  0.022646  0.005351  0.168450  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagged_seq:  [('J.P.', 'ADV'), ('Bolduc', 'ADV'), (',', '.'), ('vice', 'NOUN'), ('chairman', 'NOUN'), ('of', 'ADP'), ('W.R.', 'NOUN'), ('Grace', 'NOUN'), ('&', 'CONJ'), ('Co.', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-10', 'X'), ('holds', 'VERB'), ('a', 'DET'), ('83.4', 'ADV'), ('%', 'NOUN'), ('interest', 'NOUN'), ('in', 'ADP'), ('this', 'DET'), ('energy-services', 'ADV'), ('company', 'NOUN'), (',', '.'), ('was', 'VERB'), ('elected', 'VERB'), ('*-10', 'X'), ('a', 'DET'), ('director', 'NOUN'), ('.', '.'), ('Elisa', 'ADV'), ('Hollis', 'ADV'), ('launched', 'VERB'), ('a', 'DET'), ('diaper', 'NOUN'), ('service', 'NOUN'), ('last', 'ADJ'), ('year', 'NOUN'), ('because', 'ADP'), ('State', 'NOUN'), ('College', 'NOUN'), (',', '.'), ('Pa.', 'NOUN'), (',', '.'), ('where', 'ADV'), ('she', 'PRON'), ('lives', 'VERB'), ('*T*-1', 'X'), (',', '.'), ('did', 'VERB'), (\"n't\", 'ADV'), ('have', 'VERB'), ('one', 'NUM'), ('.', '.'), ('Rally', 'NOUN'), (\"'s\", 'PRT'), ('Inc.', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('has', 'VERB'), ('redeemed', 'VERB'), ('its', 'PRON'), ('rights', 'NOUN'), ('outstanding', 'ADJ'), ('issued', 'VERB'), ('*', 'X'), ('Monday', 'NOUN'), ('in', 'ADP'), ('its', 'PRON'), ('shareholder', 'NOUN'), ('rights', 'NOUN'), ('plan', 'NOUN'), ('.', '.'), ('A', 'DET'), ('survey', 'NOUN'), ('by', 'ADP'), ('the', 'DET'), ('Federal', 'NOUN'), ('Reserve', 'NOUN'), (\"'s\", 'PRT'), ('12', 'NUM'), ('district', 'NOUN'), ('banks', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('latest', 'ADJ'), ('report', 'NOUN'), ('by', 'ADP'), ('the', 'DET'), ('National', 'NOUN'), ('Association', 'NOUN'), ('of', 'ADP'), ('Purchasing', 'NOUN'), ('Management', 'NOUN'), ('blurred', 'ADV'), ('that', 'ADP'), ('picture', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('economy', 'NOUN'), ('.', '.'), ('``', '.'), ('Wilder', 'NOUN'), ('has', 'VERB'), ('managed', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('get', 'VERB'), ('across', 'ADP'), ('the', 'DET'), ('idea', 'NOUN'), ('that', 'ADP'), ('Coleman', 'NOUN'), ('will', 'VERB'), ('say', 'VERB'), ('anything', 'NOUN'), ('*-2', 'X'), ('to', 'PRT'), ('get', 'VERB'), ('elected', 'VERB'), ('*-3', 'X'), ('governor', 'ADV'), ('and', 'CONJ'), ('--', '.'), ('more', 'ADV'), ('important', 'ADJ'), ('--', '.'), ('has', 'VERB'), ('been', 'VERB'), ('able', 'ADJ'), ('*-1', 'X'), ('to', 'PRT'), ('put', 'VERB'), ('the', 'DET'), ('onus', 'ADV'), ('for', 'ADP'), ('all', 'DET'), ('the', 'DET'), ('negative', 'ADJ'), ('campaigning', 'NOUN'), ('on', 'ADP'), ('Coleman', 'NOUN'), ('.', '.'), (\"''\", '.')]\n",
      "Time taken in seconds:  31.398640394210815\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"tagged_seq: \", tagged_seq)\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9236111111111112\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(\"''\", '.'), (('J.P.', 'ADV'), ('J.P.', 'NOUN'))], [('J.P.', 'NOUN'), (('Bolduc', 'ADV'), ('Bolduc', 'NOUN'))], [('a', 'DET'), (('83.4', 'ADV'), ('83.4', 'NUM'))], [('this', 'DET'), (('energy-services', 'ADV'), ('energy-services', 'ADJ'))], [('.', '.'), (('Elisa', 'ADV'), ('Elisa', 'NOUN'))], [('Elisa', 'NOUN'), (('Hollis', 'ADV'), ('Hollis', 'NOUN'))], [('Management', 'NOUN'), (('blurred', 'ADV'), ('blurred', 'VERB'))], [('blurred', 'VERB'), (('that', 'ADP'), ('that', 'DET'))], [('get', 'VERB'), (('across', 'ADP'), ('across', 'PRT'))], [('*-3', 'X'), (('governor', 'ADV'), ('governor', 'NOUN'))], [('the', 'DET'), (('onus', 'ADV'), ('onus', 'NOUN'))]]\n"
     ]
    }
   ],
   "source": [
    "# incorrect tags\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "print(incorrect_tagged_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ADV', 9), ('NOUN', 9), ('DET', 4), ('VERB', 3), ('.', 2)]\n"
     ]
    }
   ],
   "source": [
    "# most frequent tag in the corpus\n",
    "def get_tagcounts(tagged_cases):\n",
    "    tag_list = []\n",
    "    for item in tagged_cases:\n",
    "        tag_list.append(item[0])\n",
    "        tag_list.append(item[1][0])\n",
    "        tag_list.append(item[1][1])\n",
    "    return tag_list\n",
    "\n",
    "tags_list = get_tagcounts(incorrect_tagged_cases)\n",
    "\n",
    "tags = [pair[1] for pair in tags_list]\n",
    "tag_counts = Counter(tags)\n",
    "# the most common tags can be seen using the most_common() method of Counter\n",
    "most_common_tags =tag_counts.most_common(5)\n",
    "print(most_common_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "#Modifying the vannila viterbi\n",
    "def Viterbi_techniqueone(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    V=[i[0] for i in train_bag]\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "     \n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]      \n",
    "            if words[key] in V:\n",
    "                state_probability = emission_p * transition_p\n",
    "            else:\n",
    "                state_probability = transition_p    #Considering only the transition prob as emission will be zero        \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)      \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagged_seq:  [('J.P.', 'NOUN'), ('Bolduc', 'NOUN'), (',', '.'), ('vice', 'NOUN'), ('chairman', 'NOUN'), ('of', 'ADP'), ('W.R.', 'NOUN'), ('Grace', 'NOUN'), ('&', 'CONJ'), ('Co.', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-10', 'X'), ('holds', 'VERB'), ('a', 'DET'), ('83.4', 'NOUN'), ('%', 'NOUN'), ('interest', 'NOUN'), ('in', 'ADP'), ('this', 'DET'), ('energy-services', 'NOUN'), ('company', 'NOUN'), (',', '.'), ('was', 'VERB'), ('elected', 'VERB'), ('*-10', 'X'), ('a', 'DET'), ('director', 'NOUN'), ('.', '.'), ('Elisa', 'NOUN'), ('Hollis', 'NOUN'), ('launched', 'VERB'), ('a', 'DET'), ('diaper', 'NOUN'), ('service', 'NOUN'), ('last', 'ADJ'), ('year', 'NOUN'), ('because', 'ADP'), ('State', 'NOUN'), ('College', 'NOUN'), (',', '.'), ('Pa.', 'NOUN'), (',', '.'), ('where', 'ADV'), ('she', 'PRON'), ('lives', 'VERB'), ('*T*-1', 'X'), (',', '.'), ('did', 'VERB'), (\"n't\", 'ADV'), ('have', 'VERB'), ('one', 'NUM'), ('.', '.'), ('Rally', 'NOUN'), (\"'s\", 'PRT'), ('Inc.', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('has', 'VERB'), ('redeemed', 'VERB'), ('its', 'PRON'), ('rights', 'NOUN'), ('outstanding', 'ADJ'), ('issued', 'VERB'), ('*', 'X'), ('Monday', 'NOUN'), ('in', 'ADP'), ('its', 'PRON'), ('shareholder', 'NOUN'), ('rights', 'NOUN'), ('plan', 'NOUN'), ('.', '.'), ('A', 'DET'), ('survey', 'NOUN'), ('by', 'ADP'), ('the', 'DET'), ('Federal', 'NOUN'), ('Reserve', 'NOUN'), (\"'s\", 'PRT'), ('12', 'NUM'), ('district', 'NOUN'), ('banks', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('latest', 'ADJ'), ('report', 'NOUN'), ('by', 'ADP'), ('the', 'DET'), ('National', 'NOUN'), ('Association', 'NOUN'), ('of', 'ADP'), ('Purchasing', 'NOUN'), ('Management', 'NOUN'), ('blurred', 'NOUN'), ('that', 'ADP'), ('picture', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('economy', 'NOUN'), ('.', '.'), ('``', '.'), ('Wilder', 'NOUN'), ('has', 'VERB'), ('managed', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('get', 'VERB'), ('across', 'ADP'), ('the', 'DET'), ('idea', 'NOUN'), ('that', 'ADP'), ('Coleman', 'NOUN'), ('will', 'VERB'), ('say', 'VERB'), ('anything', 'NOUN'), ('*-2', 'X'), ('to', 'PRT'), ('get', 'VERB'), ('elected', 'VERB'), ('*-3', 'X'), ('governor', 'VERB'), ('and', 'CONJ'), ('--', '.'), ('more', 'ADV'), ('important', 'ADJ'), ('--', '.'), ('has', 'VERB'), ('been', 'VERB'), ('able', 'ADJ'), ('*-1', 'X'), ('to', 'PRT'), ('put', 'VERB'), ('the', 'DET'), ('onus', 'NOUN'), ('for', 'ADP'), ('all', 'DET'), ('the', 'DET'), ('negative', 'ADJ'), ('campaigning', 'NOUN'), ('on', 'ADP'), ('Coleman', 'NOUN'), ('.', '.'), (\"''\", '.')]\n",
      "Time taken in seconds:  32.510319232940674\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq_unk = Viterbi_techniqueone(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"tagged_seq: \", tagged_seq_unk )\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check_unk = [i for i, j in zip(tagged_seq_unk, test_run_base) if i == j]\n",
    "accuracy_unk = len(check_unk)/len(tagged_seq_unk)\n",
    "print(accuracy_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('a', 'DET'), (('83.4', 'NOUN'), ('83.4', 'NUM'))], [('this', 'DET'), (('energy-services', 'NOUN'), ('energy-services', 'ADJ'))], [('Management', 'NOUN'), (('blurred', 'NOUN'), ('blurred', 'VERB'))], [('blurred', 'VERB'), (('that', 'ADP'), ('that', 'DET'))], [('get', 'VERB'), (('across', 'ADP'), ('across', 'PRT'))], [('*-3', 'X'), (('governor', 'VERB'), ('governor', 'NOUN'))]]\n"
     ]
    }
   ],
   "source": [
    "# incorrect tags\n",
    "incorrect_tagged_cases_unk = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq_unk, test_run_base)) if j[0]!=j[1]]\n",
    "print(incorrect_tagged_cases_unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Technique 2 using patterns to replace tags for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modifying using RegEx\n",
    "def Viterbi_techniquetwo(incorrect_tagged_cases, tagged_seq_to_improve):\n",
    "    patterns = [\n",
    "    (r'.*es$', 'VERB'),\n",
    "    (r'.*ing$', 'VERB'),\n",
    "    (r'\\d?[a-z]?-[a-z]', 'ADP'),         \n",
    "    (r'.*ed$', 'VERB'),\n",
    "    (r'^an?$|the$', 'DET'),              \n",
    "    (r'.*ful$', 'ADJ'), \n",
    "    (r'.*ous$', 'ADJ'),\n",
    "    (r'.*ble$', 'ADJ'),\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), \n",
    "    (r'.*', 'NOUN')\n",
    "    ]\n",
    "    # create a regex tagger \n",
    "    regexp_tagger = nltk.RegexpTagger(patterns)\n",
    " \n",
    "    #tag the incorrect words properly this time \n",
    "    incorrect_words=[i[1][0] for i in incorrect_tagged_cases]\n",
    "    regex_result=regexp_tagger.tag_sents(incorrect_words)\n",
    "    for i in incorrect_words[:]:\n",
    "        tagged_seq_to_improve.remove(i)\n",
    "    for i in regex_result:\n",
    "        tagged_seq_to_improve.append(i[0])\n",
    "    return tagged_seq_to_improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "#The accuracy for the modified code \n",
    "tagged_seq_validation_temp = tagged_seq_unk\n",
    "tagged_seq_validation_result = Viterbi_techniquetwo(incorrect_tagged_cases_unk, tagged_seq_validation_temp)\n",
    "\n",
    "tagged_seq_validation_result.sort()\n",
    "test_run_base.sort()\n",
    "check_validation = [i for i, j in zip(tagged_seq_validation_result, test_run_base) if i == j] \n",
    "accuracy_validation = len(check_validation)/len(tagged_seq_validation_result)\n",
    "print(accuracy_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('able', 'ADJ'), (('across', 'NOUN'), ('across', 'PRT'))], [('elected', 'VERB'), (('energy-services', 'VERB'), ('energy-services', 'ADJ'))], [('that', 'ADP'), (('that', 'NOUN'), ('that', 'DET'))]]\n"
     ]
    }
   ],
   "source": [
    "# incorrect tags\n",
    "incorrect_tag_cases_modified_validation =[[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq_validation_result, test_run_base)) if j[0]!=j[1]]\n",
    "print(incorrect_tag_cases_modified_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9236111111111112"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The validation accuracy for the vanilla viterbi is  as below \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The validation accuracy for the viterbi unknown is  as below \n",
    "accuracy_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The validation accuracy for the viterbi pattern using regex is  as below \n",
    "accuracy_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(\"''\", '.'), (('J.P.', 'ADV'), ('J.P.', 'NOUN'))],\n",
       " [('J.P.', 'NOUN'), (('Bolduc', 'ADV'), ('Bolduc', 'NOUN'))],\n",
       " [('a', 'DET'), (('83.4', 'ADV'), ('83.4', 'NUM'))],\n",
       " [('this', 'DET'), (('energy-services', 'ADV'), ('energy-services', 'ADJ'))],\n",
       " [('.', '.'), (('Elisa', 'ADV'), ('Elisa', 'NOUN'))],\n",
       " [('Elisa', 'NOUN'), (('Hollis', 'ADV'), ('Hollis', 'NOUN'))],\n",
       " [('Management', 'NOUN'), (('blurred', 'ADV'), ('blurred', 'VERB'))],\n",
       " [('blurred', 'VERB'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('get', 'VERB'), (('across', 'ADP'), ('across', 'PRT'))],\n",
       " [('*-3', 'X'), (('governor', 'ADV'), ('governor', 'NOUN'))],\n",
       " [('the', 'DET'), (('onus', 'ADV'), ('onus', 'NOUN'))]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The incorrect tag list for the vanilla viterbi is  as below \n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('a', 'DET'), (('83.4', 'NOUN'), ('83.4', 'NUM'))],\n",
       " [('this', 'DET'), (('energy-services', 'NOUN'), ('energy-services', 'ADJ'))],\n",
       " [('Management', 'NOUN'), (('blurred', 'NOUN'), ('blurred', 'VERB'))],\n",
       " [('blurred', 'VERB'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('get', 'VERB'), (('across', 'ADP'), ('across', 'PRT'))],\n",
       " [('*-3', 'X'), (('governor', 'VERB'), ('governor', 'NOUN'))]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The incorrect tag list for the viterbi unk is  as below \n",
    "incorrect_tagged_cases_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('able', 'ADJ'), (('across', 'NOUN'), ('across', 'PRT'))],\n",
       " [('elected', 'VERB'),\n",
       "  (('energy-services', 'VERB'), ('energy-services', 'ADJ'))],\n",
       " [('that', 'ADP'), (('that', 'NOUN'), ('that', 'DET'))]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The incorrect tag list for the viterbi pattern using regex is  as below \n",
    "incorrect_tag_cases_modified_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation on test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android is a mobile operating system developed by Google.\n",
      "Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.\n",
      "Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\n",
      "Twitter is an online news and social networking service on which users post and interact with messages known as tweets.\n",
      "Before entering politics, Donald Trump was a domineering businessman and a television personality.\n",
      "The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\n",
      "This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.\n",
      "Show me the cheapest round trips from Dallas to Atlanta\n",
      "I would like to see flights from Denver to Philadelphia.\n",
      "Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.\n",
      "NASA invited social media users to experience the launch of ICESAT-2 Satellite.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the test file\n",
    "test_sentence = open(\"E:/AIML/Course4-Natural Language Processing/Module3-Syntactic Processing-Assignment/Test_sentences.txt\", \"r\")\n",
    "test_text_sentence = test_sentence.read()\n",
    "test_sentence.close()\n",
    "print(test_text_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Android', 'is', 'a', 'mobile', 'operating', 'system', 'developed', 'by', 'Google', '.', 'Android', 'has', 'been', 'the', 'best-selling', 'OS', 'worldwide', 'on', 'smartphones', 'since', '2011', 'and', 'on', 'tablets', 'since', '2013', '.', 'Google', 'and', 'Twitter', 'made', 'a', 'deal', 'in', '2015', 'that', 'gave', 'Google', 'access', 'to', 'Twitter', \"'s\", 'firehose', '.', 'Twitter', 'is', 'an', 'online', 'news', 'and', 'social', 'networking', 'service', 'on', 'which', 'users', 'post', 'and', 'interact', 'with', 'messages', 'known', 'as', 'tweets', '.', 'Before', 'entering', 'politics', ',', 'Donald', 'Trump', 'was', 'a', 'domineering', 'businessman', 'and', 'a', 'television', 'personality', '.', 'The', '2018', 'FIFA', 'World', 'Cup', 'is', 'the', '21st', 'FIFA', 'World', 'Cup', ',', 'an', 'international', 'football', 'tournament', 'contested', 'once', 'every', 'four', 'years', '.', 'This', 'is', 'the', 'first', 'World', 'Cup', 'to', 'be', 'held', 'in', 'Eastern', 'Europe', 'and', 'the', '11th', 'time', 'that', 'it', 'has', 'been', 'held', 'in', 'Europe', '.', 'Show', 'me', 'the', 'cheapest', 'round', 'trips', 'from', 'Dallas', 'to', 'Atlanta', 'I', 'would', 'like', 'to', 'see', 'flights', 'from', 'Denver', 'to', 'Philadelphia', '.', 'Show', 'me', 'the', 'price', 'of', 'the', 'flights', 'leaving', 'Atlanta', 'at', 'about', '3', 'in', 'the', 'afternoon', 'and', 'arriving', 'in', 'San', 'Francisco', '.', 'NASA', 'invited', 'social', 'media', 'users', 'to', 'experience', 'the', 'launch', 'of', 'ICESAT-2', 'Satellite', '.']\n"
     ]
    }
   ],
   "source": [
    "## convert into word\n",
    "#sentence_test = test_sentence.to_string(buf=None, columns=None, index=False)\n",
    "words = word_tokenize(test_text_sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_tagged_test_sentence [('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'DET'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.'), ('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'ADJ'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'NOUN'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'ADJ'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'NUM'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'VERB'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'VERB'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'VERB'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADV'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'NOUN'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'VERB'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Tag words using POS\n",
    "pos_tagged_test_sentence = nltk.pos_tag(words, tagset='universal')\n",
    "print(\"pos_tagged_test_sentence\", pos_tagged_test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'ADV'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'ADV'), ('.', '.'), ('Android', 'ADV'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'ADV'), ('worldwide', 'ADV'), ('on', 'ADP'), ('smartphones', 'ADV'), ('since', 'ADP'), ('2011', 'ADV'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'ADV'), ('.', '.'), ('Google', 'ADV'), ('and', 'CONJ'), ('Twitter', 'ADV'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'ADV'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'ADV'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'ADV'), (\"'s\", 'PRT'), ('firehose', 'ADV'), ('.', '.'), ('Twitter', 'ADV'), ('is', 'VERB'), ('an', 'DET'), ('online', 'ADV'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'ADV'), ('with', 'ADP'), ('messages', 'ADV'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'ADV'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'ADV'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'ADV'), ('.', '.'), ('The', 'DET'), ('2018', 'ADV'), ('FIFA', 'ADV'), ('World', 'NOUN'), ('Cup', 'ADV'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'ADV'), ('FIFA', 'ADV'), ('World', 'NOUN'), ('Cup', 'ADV'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'ADV'), ('contested', 'ADV'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'ADV'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'ADV'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'ADV'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'ADV'), ('invited', 'ADV'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'ADV'), ('Satellite', 'ADV'), ('.', '.')]\n",
      "42.357197523117065\n"
     ]
    }
   ],
   "source": [
    "# Validation to run on Viterbi\n",
    "start = time.time()\n",
    "word_tagged_seq = Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(word_tagged_seq)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7624309392265194\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "word_check = [i for i, j in zip(word_tagged_seq, pos_tagged_test_sentence) if i == j] \n",
    "word_accuracy = len(word_check)/len(word_tagged_seq)\n",
    "print(word_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('.', '.'), (('Android', 'ADV'), ('Android', 'NOUN'))], [('by', 'ADP'), (('Google', 'ADV'), ('Google', 'NOUN'))], [('.', '.'), (('Android', 'ADV'), ('Android', 'NOUN'))], [('best-selling', 'ADJ'), (('OS', 'ADV'), ('OS', 'NOUN'))], [('OS', 'NOUN'), (('worldwide', 'ADV'), ('worldwide', 'NOUN'))], [('on', 'ADP'), (('smartphones', 'ADV'), ('smartphones', 'NOUN'))], [('since', 'ADP'), (('2011', 'ADV'), ('2011', 'NUM'))], [('since', 'ADP'), (('2013', 'ADV'), ('2013', 'NUM'))], [('.', '.'), (('Google', 'ADV'), ('Google', 'NOUN'))], [('and', 'CONJ'), (('Twitter', 'ADV'), ('Twitter', 'NOUN'))], [('in', 'ADP'), (('2015', 'ADV'), ('2015', 'NUM'))], [('2015', 'NUM'), (('that', 'ADP'), ('that', 'DET'))], [('gave', 'VERB'), (('Google', 'ADV'), ('Google', 'NOUN'))], [('to', 'PRT'), (('Twitter', 'ADV'), ('Twitter', 'NOUN'))], [(\"'s\", 'PRT'), (('firehose', 'ADV'), ('firehose', 'NOUN'))], [('.', '.'), (('Twitter', 'ADV'), ('Twitter', 'NOUN'))], [('an', 'DET'), (('online', 'ADV'), ('online', 'ADJ'))], [('and', 'CONJ'), (('interact', 'ADV'), ('interact', 'NOUN'))], [('with', 'ADP'), (('messages', 'ADV'), ('messages', 'NOUN'))], [('as', 'ADP'), (('tweets', 'ADV'), ('tweets', 'NOUN'))], [('a', 'DET'), (('domineering', 'ADV'), ('domineering', 'ADJ'))], [('television', 'NOUN'), (('personality', 'ADV'), ('personality', 'NOUN'))], [('The', 'DET'), (('2018', 'ADV'), ('2018', 'NUM'))], [('2018', 'NUM'), (('FIFA', 'ADV'), ('FIFA', 'NOUN'))], [('World', 'NOUN'), (('Cup', 'ADV'), ('Cup', 'NOUN'))], [('the', 'DET'), (('21st', 'ADV'), ('21st', 'NUM'))], [('21st', 'NUM'), (('FIFA', 'ADV'), ('FIFA', 'NOUN'))], [('World', 'NOUN'), (('Cup', 'ADV'), ('Cup', 'NOUN'))], [('football', 'NOUN'), (('tournament', 'ADV'), ('tournament', 'NOUN'))], [('tournament', 'NOUN'), (('contested', 'ADV'), ('contested', 'VERB'))], [('World', 'NOUN'), (('Cup', 'ADV'), ('Cup', 'NOUN'))], [('the', 'DET'), (('11th', 'ADJ'), ('11th', 'NUM'))], [('.', '.'), (('Show', 'NOUN'), ('Show', 'VERB'))], [('round', 'NOUN'), (('trips', 'ADV'), ('trips', 'NOUN'))], [('would', 'VERB'), (('like', 'ADP'), ('like', 'VERB'))], [('.', '.'), (('Show', 'NOUN'), ('Show', 'VERB'))], [('at', 'ADP'), (('about', 'ADP'), ('about', 'ADV'))], [('and', 'CONJ'), (('arriving', 'ADV'), ('arriving', 'NOUN'))], [('.', '.'), (('NASA', 'ADV'), ('NASA', 'NOUN'))], [('NASA', 'NOUN'), (('invited', 'ADV'), ('invited', 'VERB'))], [('to', 'PRT'), (('experience', 'NOUN'), ('experience', 'VERB'))], [('of', 'ADP'), (('ICESAT-2', 'ADV'), ('ICESAT-2', 'NOUN'))], [('ICESAT-2', 'NOUN'), (('Satellite', 'ADV'), ('Satellite', 'NOUN'))]]\n"
     ]
    }
   ],
   "source": [
    "# Incorrect Tags\n",
    "incorrect_tagged_cases_word = [[pos_tagged_test_sentence[i-1],j] for i, j in enumerate(zip(word_tagged_seq, pos_tagged_test_sentence)) if j[0]!=j[1]]\n",
    "print(incorrect_tagged_cases_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'DET'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'DET'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.'), ('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'DET'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'DET'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'NOUN'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "44.87232756614685\n"
     ]
    }
   ],
   "source": [
    "# Validation to run on Viterbi unknown\n",
    "start = time.time()\n",
    "word_tagged_seq_unk = Viterbi_techniqueone(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(word_tagged_seq_unk)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8674033149171271\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "word_check_unk = [i for i, j in zip(word_tagged_seq_unk, pos_tagged_test_sentence) if i == j] \n",
    "word_accuracy_unk = len(word_check_unk)/len(word_tagged_seq_unk)\n",
    "print(word_accuracy_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('by', 'ADP'), (('Google', 'DET'), ('Google', 'NOUN'))], [('on', 'ADP'), (('smartphones', 'DET'), ('smartphones', 'NOUN'))], [('since', 'ADP'), (('2011', 'DET'), ('2011', 'NUM'))], [('since', 'ADP'), (('2013', 'DET'), ('2013', 'NUM'))], [('in', 'ADP'), (('2015', 'DET'), ('2015', 'NUM'))], [('2015', 'NUM'), (('that', 'ADP'), ('that', 'DET'))], [('gave', 'VERB'), (('Google', 'X'), ('Google', 'NOUN'))], [('to', 'PRT'), (('Twitter', 'VERB'), ('Twitter', 'NOUN'))], [(\"'s\", 'PRT'), (('firehose', 'VERB'), ('firehose', 'NOUN'))], [('an', 'DET'), (('online', 'NOUN'), ('online', 'ADJ'))], [('with', 'ADP'), (('messages', 'DET'), ('messages', 'NOUN'))], [('as', 'ADP'), (('tweets', 'DET'), ('tweets', 'NOUN'))], [('a', 'DET'), (('domineering', 'NOUN'), ('domineering', 'ADJ'))], [('The', 'DET'), (('2018', 'NOUN'), ('2018', 'NUM'))], [('the', 'DET'), (('21st', 'NOUN'), ('21st', 'NUM'))], [('tournament', 'NOUN'), (('contested', 'NOUN'), ('contested', 'VERB'))], [('the', 'DET'), (('11th', 'ADJ'), ('11th', 'NUM'))], [('.', '.'), (('Show', 'NOUN'), ('Show', 'VERB'))], [('would', 'VERB'), (('like', 'ADP'), ('like', 'VERB'))], [('.', '.'), (('Show', 'NOUN'), ('Show', 'VERB'))], [('at', 'ADP'), (('about', 'ADP'), ('about', 'ADV'))], [('NASA', 'NOUN'), (('invited', 'NOUN'), ('invited', 'VERB'))], [('to', 'PRT'), (('experience', 'NOUN'), ('experience', 'VERB'))], [('of', 'ADP'), (('ICESAT-2', 'DET'), ('ICESAT-2', 'NOUN'))]]\n"
     ]
    }
   ],
   "source": [
    "# Incorerct Tags\n",
    "incorrect_tagged_cases_word_unk = [[pos_tagged_test_sentence[i-1],j] for i, j in enumerate(zip(word_tagged_seq_unk, pos_tagged_test_sentence)) if j[0]!=j[1]]\n",
    "print(incorrect_tagged_cases_word_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9337016574585635\n"
     ]
    }
   ],
   "source": [
    "#The validation accuracy for the modified code using regex\n",
    "tagged_seq_validation_regex = word_tagged_seq_unk\n",
    "tagged_seq_validation_result_regex = Viterbi_techniquetwo(incorrect_tagged_cases_word_unk, tagged_seq_validation_regex)\n",
    "\n",
    "tagged_seq_validation_result_regex.sort()\n",
    "pos_tagged_test_sentence.sort()\n",
    "check_validation_regex = [i for i, j in zip(tagged_seq_validation_result_regex, pos_tagged_test_sentence) if i == j] \n",
    "accuracy_validation_regex = len(check_validation_regex)/len(tagged_seq_validation_result_regex)\n",
    "print(accuracy_validation_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('.', '.'), (('11th', 'NOUN'), ('11th', 'NUM'))], [('2018', 'NUM'), (('21st', 'NOUN'), ('21st', 'NUM'))], [('Satellite', 'NOUN'), (('Show', 'NOUN'), ('Show', 'VERB'))], [('Show', 'VERB'), (('Show', 'NOUN'), ('Show', 'VERB'))], [('a', 'DET'), (('about', 'NOUN'), ('about', 'ADV'))], [('developed', 'VERB'), (('domineering', 'VERB'), ('domineering', 'ADJ'))], [('every', 'DET'), (('experience', 'NOUN'), ('experience', 'VERB'))], [('leaving', 'VERB'), (('like', 'NOUN'), ('like', 'VERB'))], [('media', 'NOUN'), (('messages', 'VERB'), ('messages', 'NOUN'))], [('once', 'ADV'), (('online', 'NOUN'), ('online', 'ADJ'))], [('since', 'ADP'), (('smartphones', 'VERB'), ('smartphones', 'NOUN'))], [('that', 'ADP'), (('that', 'NOUN'), ('that', 'DET'))]]\n"
     ]
    }
   ],
   "source": [
    "# Incorrect tags\n",
    "incorrect_tagged_cases_word_regex = [[pos_tagged_test_sentence[i-1],j] for i, j in enumerate(zip(tagged_seq_validation_result_regex, pos_tagged_test_sentence)) if j[0]!=j[1]]\n",
    "print(incorrect_tagged_cases_word_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
